
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>ECE 5160: Fast Robot  |  Michael Wu</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

    <!-- Custom styles for this template -->
    <link href="starter-template.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <!-- <script src="../../assets/js/ie-emulation-modes-warning.js"></script> -->

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">ECE 5160: Fast Robot  |  Michael Wu </a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class="active"><a href="#">Home</a></li>
            <li><a href="#lab1">Lab 1</a></li>
            <li><a href="#lab2">Lab 2</a></li>
            <li><a href="#lab3">Lab 3</a></li>
            <li><a href="#lab4">Lab 4</a></li>
            <li><a href="#lab5">Lab 5</a></li>
            <li><a href="#lab6">Lab 6</a></li>
            <li><a href="#about">About</a></li>
            <li><a href="#lab7">Lab 7</a></li> 
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <div class="starter-template">
        <h1>Cornell University ECE5160 Fast Robot</h1>
        <p class="lead"> Project Website By Michael Wu</p>
      </div>

    <hr id="lab1">
    <br>
      <div style="text-align:center;">
              <h2>Lab 1: The Artemis board</h2>
              <h3>Introduction</h3>
              <p style="text-align: left;padding: 0px 30px;"> In lab 1, we setup Arudino IDE and tested the Apollo Artemis board over the IDE. The main goal of this lab is to
              get used to programming the board using Arduino IDE. Following the lab 1 spec, we first installed Arduino with Artemis board support, and then tested five different scripts, including Blinking, Serial, AnalogRead, MicrophoneOutput, and LED control by microphone, observing and verifying their functionalities.</p>
              <hr>

              <h3>Arduino IDE Setup</h3>
              <p style="text-align: left;padding: 0px 30px;"> The lastest vresion 2.0.3 of Arduino IDE was downloaded from the Arudino official website and installed for the prelab. Following <a href="https://learn.sparkfun.com/tutorials/artemis-development-with-arduino?_ga=2.30055167.1151850962.1594648676-1889762036.1574524297&_gac=1.19903818.1593457111.Cj0KCQjwoub3BRC6ARIsABGhnyahkG7hU2v-0bSiAeprvZ7c9v0XEKYdVHIIi_-J-m5YLdDBMc2P_goaAtA4EALw_wcB"> Sparkfun setup instructions</a>, I put an additional URL in Files > Preferences > Additional Board Manager URL, and then installed the lastest version of Apollo3 Board package via Tools > Board > Board Manager and search for Apollo. Note that even after the installation of the Apollo3 package, plugging the Apollo board in the PC through USB, and selecting the correct COM port for the board, there was still not a option of SparkFun BlackBoard Artemis, which was shown in the sparkfun tutorial. Therefore, I choose RedBoard Artemis Nano as my board and confirmed my selection with the TA. As a result, the scripts I ran for the following sections can be in a different directory than described in lab1 tutorial.</p>
              <hr>

              <h3>Blink</h3>
              <p style="text-align: left;padding: 0px 30px;"> The first script we ran on our board was the example blink script. Going to File > Examples > 01.Basics > Blink, we compiled and executed the blink script without changing the baud rate. In the Blink script, we repetitively write the built-in LED to high, delay for a second, write the LED to LOW, delay for a second to generate a blinky effect. From the testing video below, we could observe that the built-in LED on the board started to to blink by a repetitive sequence of turning on to blue, resting for a second, turning off, and resting for a second. This observation met our expecatation and the blink test was successful.</p>
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/EF8L7n0hbrk" frameborder="0" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 1 Video 1: Blink</h4>
              </div>
              <hr>

              <h3>Serial</h3>
              <p style="text-align: left;padding: 0px 30px;"> The second test Serial output from a serial montior of the Arudino IDE. Serial Output, or UART, sends output stream to the serior monitor of the Arduino IDE. Similar to the printf in C and cout statments in C++, Serial.println() in the Arduino syntax allows printing strings and values of parameters, which could be very helpful for debugging. The only additional step we need to do here is to set a baud rate for data transmission by Serial.begin(115200), where 115200 Hz is the baud rate used in this example. On the other hand, we opened the serial monitor of the Arduino IDE BY clicking on the magnifier-like icon on the top-right corner of the IDE and set the baud rate to 115200 as well.<br>
              Note that instead of going to File > Examples > Artemis Examples > Example2_Serial, I had to go to File > Examples > Apollo3 > Example4_Serial to execute the script. <br>
              From the video below, we could oberserve that at first 10 lines with increased count numbers were printed, and then the program listened to whatever the user inputted via the keyboard, echoing and printing the input message via the serial monitor. Thus Serial was working!</p>
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/tyZdv4GpHZw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 1 Video 2: Serial</h4>
              </div>             
              <hr>

              <h3>AnalogRead</h3>
              <p style="text-align: left;padding: 0px 30px;"> In the third example, we tested the functionality of Analog Read. The board we used had an internal termperature sensor and the example AnalogRead program used an internal Analog-Digital-Converter(ADC) to get the temperature readings from the temperature sensor and repeatly printed those readings to the serial monitor. <br>
              Note that instead of going to File > Examples > Artemis Examples > Example4_Analog, I had to go to File > Examples > Apollo3 > Example2_AnalogRead to execute the script. <br> 
              From the video below, we could oberserve that the second column of output -- temp (Counts) -- gradually increased from 33300 to 33500 after my finger covered the temperature sensor of the board, and gradually decreased from 33500 back to 33300 after I removed my finger, which showed the Analog Read Script was working as expected! </p>
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/fn4Wil9Vz_o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 1 Video 3: AnalogRead</h4>
              </div>
              <hr>

              <h3>PDM</h3>
              <p style="text-align: left;padding: 0px 30px;"> The fourth example used the PDM script which further utilized the Pulse-density-modulation(PDM) microphone on the board. This example script continously captured the sound around the microphone, performed Fast Fourier Transform(FFT), and printed out the loudest audio frequency to the serial monitor. <br>
              From the video below, we could oberserve that the loudest frequencies printed out initially were random values, which was caused by background noise when recording the video. However, when I put a sound source, a online tone generator on my mobile phone, close enough to the chip, we could clearly see the printed values were in accordance with and very close to the set values on the tone generator. 434 Hz - 434 Hz, 757 Hz - 755 Hz, 1224 Hz - 1224 Hz, 2162 Hz - 2174 Hz, etc. This demonstrated PDM succcessfully. </p>
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/tPtjgdi_TdY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 1 Video 4: PDM</h4>
              </div>
              <hr>

              <h3>Meng Extra: "A" note to turn on LED</h3>
              <p style="text-align: left;padding: 0px 30px;"> For the additional task for 5000-level students, we were required to to program the board such that its built-in LED was turned on when we played a musical "A" note over the spearker, and otherwise remained off. To achieve this effect, I first decided to use A4 (440 Hz) as the detection frequency. Second, I modified the PDM script in last section by (1) change the return type of the printloudest function such that the loudest frequency can be returned.</p>
              <div align="left";> 
                <h4> Original function </h4>
                <pre><code>
                void printLoudest(void) {
                  ...
                  ui32LoudestFrequency = (sampleFreq * ui32MaxIndex) / pdmDataBufferSize;
                  ...

                }

                </code></pre>
                <h4> Changed function </h4>
                <pre><code>
                uint32_t printLoudest(void) {
                  ...
                  ui32LoudestFrequency = (sampleFreq * ui32MaxIndex) / pdmDataBufferSize;
                  ...
                  return (ui32LoudestFrequency);

                }

                </code></pre>
              </div>
              <p style="text-align: left;padding: 0px 30px;"> (2) Initialize digital pin LED_BUILTIN as an output. </p>
               <div align="left";> 
                <pre><code>
                // initialize digital pin LED_BUILTIN as an output.
                pinMode(LED_BUILTIN, OUTPUT);
                </code></pre>
              </div>
              <p style="text-align: left;padding: 0px 30px;"> (3) Read return value (loudest frequency) and turn built-in LED on if the returned value is close to 440 Hz. </p>
               <div align="left";> 
                <pre><code>
                uint32_t result = printLoudest();
                if (result <= 450 && result >= 430) {
                  digitalWrite(LED_BUILTIN, HIGH);
                } else {
                  digitalWrite(LED_BUILTIN, LOW);
                }
                </code></pre>
              </div>
              <p style="text-align: left;padding: 0px 30px;"> 
              From the video below, we could oberserve that the blue LED was turned on only when the output frequency from the tone generator was close to 440 Hz, thus proving the correctness of the code design.</p>
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/aK7hO3O-LW0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 1 Video 5: Meng Extra: "A" note to turn on LED</h4>
              </div>

      </div>



    <hr id='lab2'>
      <br>
      <div style="text-align:center;">
              <h2>Lab 2 : Bluetooth</h2>
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;"> In lab 3, we explore the use of two Time-of </p>
              <hr>

              <h2>Prelab</h2>
              <h3>Setup</h3>
              <p style="text-align: left;padding: 0px 30px;"> To set up my own PC, I follow the steps in the tutorial. <br> (1) Install Python3 and Pip.   <br>
                <img class="img-rounded" src="pics/lab2/lab2-1.png" alt="Generic placeholder image" height="100"> <br>(2) Install and set up virtual environment. <br>(3) activate the virtual environment, install python packages, and open Jupyter notebook. <br> (4) Run the example arduino code to get the MAC address of the board. Update connection.yaml with this MAC address.<img class="img-rounded" src="pics/lab2/lab2-2.png" alt="Generic placeholder image"> <br>(5) Run uuid4() on Jupyter notebook to generate a UUID. <br> (6) Update base_ble.py for Windows. <br> (7) Update ble_service and yaml configuration to have the same UUID.  <br> (7) Run demo.ipynb and received a error saying OS not supported (Windows 11). Switched to a lab PC and repeat (1) to (7) to get things working.</p>
              <hr>

              <h3>Codebase</h3>
              <p style="text-align: left;padding: 0px 30px;"> On the Arduino side, the BLE library is used so that our board serves as a bluetooth peripheral: different BLE UUIDs taking care of different kind of data, BLE service providing three characteristics: BLEFloatCharacteristic, BLEIntCharacteristic, and BLECStringCharacteristic. The user uses different BLE functions along with Estrings to write these characteristics for sending data to PC. <br>
              On the PC side, the python scripts set up a BLE controller and can detect the BLE device (Artemis Board). PC can read from characteristics or send data via different cmd commands. 
              Both sides use RX and TX. 
              <hr>

              <h2>Lab Tasks</h2>
              <h3>configurations</h3>
              <p style="text-align: left;padding: 0px 30px;"> From the pictures below and in the setup, we can see the UUIDs and addresses match in arduino and python files.</p>
        
              <img class="img-rounded" src="pics/lab2/lab2-3.png" alt="Generic placeholder image">
              <img class="img-rounded" src="pics/lab2/lab2-4.png" alt="Generic placeholder image">
              <h3>Echo</h3>
              <p style="text-align: left;padding: 0px 30px;"> The ECHO command requires a string type of data being sent from the PC to the Artemis Board, as well as an agumented string type of data being sent/echoed back from the board to the PC. To achieve this, </p>
              <p style="text-align: left;padding: 0px 30px;"> (1) In ble.arduino.ino, add ECHO to the command types and implement the ECHO switch case as a cmd type in handle_command(). The program extracts the string value sent from the PC and store it in a char array. The arugmented string is formed by a concatenation of a prefix, the char array, and a postfix in a straightfforward way. By using the estring library, I clear the tx_estring, append the prefix, char array, and postfix sequentailly, convert to sting to c string and send it back to the PC. </p>
               <div align="left";> 
                <pre><code>
                  enum CommandTypes
                {
                    ...

                    ECHO,

                    ...
                };

                ... 
                
                void handle_command() {
                  ... 
                  switch(cmd_type) {
                  ...
                  /*
                   * Add a prefix and postfix to the string value extracted from the command string
                   */
                  case ECHO:

                      char char_arr[MAX_MSG_SIZE];

                      // Extract the next value from the command string as a character array
                      success = robot_cmd.get_next_value(char_arr);
                      if (!success)
                          return;
                      tx_estring_value.clear();
                      tx_estring_value.append("Robot Says: ");
                      tx_estring_value.append(char_arr);
                      tx_estring_value.append(" :)");
                      tx_characteristic_string.writeValue(tx_estring_value.c_str());
                      
                      break;
                  }
                }
                </code></pre>
                </div>

             <p style="text-align: left;padding: 0px 30px;"> (2) On the PC side, in a .ipynb file, add a code block that intializes and connects the PC and the board via blue tooth, as well as sending a ECHO CMD command along with a string from the PC to the board. Then the PC receives a string echoed back from the board, we store it and print it out to verify the correctness of our code. </p>
               <div align="left";> 
                <pre><code>
                ## Echo

                # Get ArtemisBLEController object
                ble = get_ble_controller()

                # Connect to the Artemis Device
                ble.connect()
                ble.send_command(CMD.ECHO, "Hi Michael!")
                s = ble.receive_string(ble.uuid['RX_STRING'])
                print(s)
                </code></pre>
                </div>

              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/MRQYbszbRDs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 2 Video 1: Echo</h4>
              </div>
      
              <hr>

              <h3>Get Time Millis</h3>
              <p style="text-align: left;padding: 0px 30px;"> (Code shown in the video) At here, we want a new command GET_TIME_MILLIS which requires the robot sent the time elapsed in milliseconds to the PC. To do this, on the robot side, we first clear the estring, and then added time by calling millis(), and write value to the tx string characteristic using the estrings. Note that I convert millis() from unsigned long to int so that estring did not throw a complaint. On the PC side, I call the command and read the received string characteristic.<br>
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/uJ80e9ePeGU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 2 Video 2: Get Time Millis</h4>
              </div>             
              <hr>

              <h3>Notification Handler</h3>
              <p style="text-align: left;padding: 0px 30px;"> For the notification handler, whose code implementation is in the video below , I write a callback function that takes UUID and bytearray and is activated by ble.start_notify. Therefore, whenever there is an update to the RX string (PC receiving data from the board), the nofitication handler is going to take the bytearray, convert to float, and store the updated data in a global variable. I did not call ble.stop_notify so that the PC side could constantly check and update the global list by the new data sets. At this, get time millis is tested for the handler and we can see the time value is only getting updated when a new ble.sendcommand() is called (a new value is sent from Arduino to PC).</p>
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/ZmR6cKGYI4E" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 2 Video 3: Notification Handler</h4>
              </div>             
              <hr>

              <h3>GET_TEMP_5S</h3>
              <p style="text-align: left;padding: 0px 30px;"> For get temperature in 5 seconds, we are asked to send an array of five timestamped internal die temperature readings from the Arduino to the PC. To do this, on the Arduino side, I first clear the tx estring, and then append five pairs of time+temperature data, with a delay of 1 second between colloecting each subsequent pair of data. The maximum estring length is 151, which is enough for five pairs of time+temp data. From the output, we can see the five pairs of time and temperature data are correct. Then I update the notification handler to extract the correct time and temperature data and put them in two respective global lists: time and temperature, whose values meet our expectation as we print them out in the video.  </p>
              <img class="img-rounded" src="pics/lab2/lab2-8.png" alt="Generic placeholder image" height="300"> 
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/F8rORZPcuWU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 2 Video 4: GET_TEMP_5S</h4>
              </div>             
              <hr>

              <h3>GET_TEMP_5s_RAPID</h3>
              <p style="text-align: left;padding: 0px 30px;"> For this task, we are asked to send a array of 5 seconds of rapidly collected data. To this end, wo modified the above code snippet by changing the delay in each iteration and adding an additional outer loop. In other words, we collect five pairs of time and temperature data, add them to the estring, send the data, and repeat these three steps for 100 times with a delay of 10 milliseconds between each. The delay time is shortened proportionally to match the requirement of total time of 5 seconds. Printing the list values we can see there are 500 pairs of time and temp data, where time[0] corresponds to temp[0] and so on.  This is because each estring has 5 pairs and there are 100 estrings in total. Note that the data are not in time order because we have no guarantee that the PC side will receive everything in the exact same order that the Arduino side sent them.</p>
              <img class="img-rounded" src="pics/lab2/lab2-9.png" alt="Generic placeholder image" height="300"> 
              <div class="center-block">
                <iframe width="640" height="360" src="https://www.youtube.com/embed/b3WnrI4fF-s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <h4 style="text-align:center;">Lab 2 Video 5: GET_TEMP_5s_RAPID</h4>
              </div>             
              <hr>

              <h3>Limitations</h3>
              <p style="text-align: left;padding: 0px 30px;"> The Artemis Board has 384kB of RAM which means 384000 bytes. Our setup is to send 5 seconds of 16-bit values taken at 150 Hz, which means 2 byte * 5 seconds * 150 cycles/second = 1500 bytes. Diving 384000 over 1500 results in 256. In other words, the Artemis Board is going to perform this action of "send 5 seconds of 16-bit values taken at 150 Hz" for at most 256 times before running out of RAM memory space, which is somewhat limited. </p>    
              <hr>

             <h3>Effective Data Rate</h3>
              <p style="text-align: left;padding: 0px 30px;"> For this part, I get the idea from <a href="https://qd39l.github.io/fast-robots/lab2.html"> 2022 student Owen Deng's Lab 2 website. </a> The arduino side is like using the ECHO command, constantly receiving different strings from the PC and sending them back. The PC side (code below) continously sends strings ranging from a size of 5 to 120 (not exceeding max string length) and record the time for sending and receiving each string with a certain size. Note that 10 trials are performed for each size length and average is computed to reduce error. From the plot below, we can see a clear positive relationship between the Message size in bytes and Time in seconds, which makes sense since longer words take longer to send and receive. Shorter words tend to have lower overhead while longer words having the opposite.</p>  
              <img class="img-rounded" src="pics/lab2/lab2-7.png" alt="Generic placeholder image" height="450">  
              <img class="img-rounded" src="pics/lab2/lab2-5.png" alt="Generic placeholder image"  height="700">          
              <hr>

             <h3>Reliability</h3>
              <p style="text-align: left;padding: 0px 30px;"> To test reliability, we need to increase the rate of data transmission from the Artemis board to the PC. To do so, I modified the GET_TEMP_5s_RAPID further on the Arduino side by reducing the delay time for each iteration to 1 millisecond only. The outermost loop is changed from 100 to 1000 to match the 5-second requirement. On the PC side, we can see that all 5000 pairs of time and temp data are received correctly and none of them are empty. Based on this, we can conclude that the computer is still able to read everything without miss anything from the board even at a very high rate.</p>  
              <img class="img-rounded" src="pics/lab2/lab2-10.png" alt="Generic placeholder image" height="400">
              <img class="img-rounded" src="pics/lab2/lab2-6.png" alt="Generic placeholder image" height="600">         
              <hr>

      </div>

    <hr id='lab3'>
    <br>
      <div style="text-align:center;">
              <h2>Lab 3 : Time of Flight Sensors</h2>
              <h2>Introduction</h2>
              <p style="text-align: left;padding: 0px 30px;"> In lab 3, we explore the use of two Time of Flight (TOF) sensors. We play around and test these sensors under different conditions for their future use associated with the actual robotic car. We would like to have a good rate and accuracy with sampling so that our robot can perform well. </p>
              <hr>

              <h2>Prelab</h2>
              <h3>I2C address</h3>
              <p style="text-align: left;padding: 0px 30px;"> From the datasheet, we know the default I2C address of any ToF sensor is 0x52. Note that using only one ToF sensor with the default I2C address is fine but using two of them at the same time can cause address conflicts such that the board would get confused. <br>
                <img class="img-rounded" src="pics/lab3/lab3-1.png" alt="Generic placeholder image" height="400"> </p>
              <hr>

              <h3>Approach to use</h3>
              <p style="text-align: left;padding: 0px 30px;"> My approach is resolve this issue is to use the shutdown pins to shut one sensor down and set the I2C address of the other sensor to a different and non-conflicting one. Therefore, when the board (master) reads the addresses of the ToFs (slaves), it will get different addresses.  </p>
              <hr>

              <h3>Placement</h3>
              <p style="text-align: left;padding: 0px 30px;"> I would like to place one sensor in the front of the car and the other on the side of the car. On one hand, the front sensor will be able to detect obstacles in front of the cars and the side sensor will be able to detect obstacles while the car is turning. My placement sacrifices part of the accuracy from placing both sensors in the front of the car for the more angle/range of measurement from different directions. However, I will still be unable to detect obstacles on the other side or at the back of the car where no sensor is installed. So in my future algorithm design, I will try to avoid those situations. </p>
              <hr>

              <h3>Wiring Diagram</h3>
              <p style="text-align: left;padding: 0px 30px;">  </p>
              <img class="img-rounded" src="pics/lab3/lab3-11.png" alt="Generic placeholder image"  height="600" >
              <hr>

              <h2>Lab Tasks</h2>
              <h3>ToF sensor connections</h3>
              <p style="text-align: left;padding: 0px 30px;"> The left picture shows connection of both ToF sensors to the QWIIC breakout board and furthre to the Artemis board. Note that red wire is for voltage, black wire is for ground, yellow wire is for SCL and orange wire is for SDA. The right picture shows where the shutdown pins of both sensors are soldered by blue wires onto the board. (pin 8 and pin 10).</p>
              <div align="center";> 
              <img class="img-rounded" src="pics/lab3/lab3-7.jpg" alt="Generic placeholder image"  height="400" >
              <img class="img-rounded" src="pics/lab3/lab3-9.jpg" alt="Generic placeholder image"  height="400" >
              </div>
              <hr>
              <h3>Artemis Scanning for I2C</h3>
              <p style="text-align: left;padding: 0px 30px;">To do this part, I detached one of the two sensors and burned Example05_Wire_I2C into the board. As shown below, scanning results in an address of 0x29. This is because the last bit for the original address 0x52 stands for read and write and when Artemis reads the I2C address, it disregard this LSB by right shifting one bit, resulting a change from 01010010 to 00101001, or from 0x52 to 0x29.</p>
              <img class="img-rounded" src="pics/lab3/lab3-2.png" alt="Generic placeholder image"  height="300" >
              <hr>

              <h3>Choose Range Mode</h3>
              <p style="text-align: left;padding: 0px 30px;"> There are three ToF modes. Short mode with a detection range of 1.3m, medium mode with a detection range of 3m, and a long default mode of a detection range of 4m. Note that distanceSensor.setDistanceModeMedium() is not actually included in the Sparkfun_VL53L1X.h header file. According to the datasheet of the sensors, the short mode gets affected by the ambient light the least, resulting in its relatively better performance than the medium and long range modes in bad enviornments. Plus I think 1.3 meter is a long enough distance for the robot to detect obstacles and take actions. Therefore, I would like to select the short mode. To create accurate measurement, I take off the protection firm from one sensor and place it as shown in the follwing picture. The sensor is held upright to the table and the box is used as the obstacle getting detected by the sensor. A ruler is used for actual distance indication.</p>
              <img class="img-rounded" src="pics/lab3/lab3-8.jpg" alt="Generic placeholder image"  height="400">
              <p style="text-align: left;padding: 0px 30px;"> Measurements result in the following picture and plots:  </p>
              <img class="img-rounded" src="pics/lab3/lab3-10.png" alt="Generic placeholder image"  height="400">
              <br> <br>
              <img class="img-rounded" src="pics/lab3/lab3-14.png" alt="Generic placeholder image"  height="400">
              <br> <br>
              <img class="img-rounded" src="pics/lab3/lab3-15.png" alt="Generic placeholder image"  height="400">
              <br> <br>
              <p style="text-align: left;padding: 0px 30px;"> I measured the distance from 70mm to 140 mm. From the plots, we can see that the measured distance is very close to the actual distance. The absoute errors and standard deviations fluctuate but stay close to zero. This means our sensor get pretty accurate measurements. </p>
              <hr>

              <h3>Two sensors in parallel</h3>
              <p style="text-align: left;padding: 0px 30px;"> To get sensors work in parallel, I use the shutdown pin of one sensor, shut it down and set the address of the other sensor to 0x32 by the code below.</p>
              <img class="img-rounded" src="pics/lab3/lab3-3.png" alt="Generic placeholder image"  height="100">
              <p style="text-align: left;padding: 0px 30px;"> Next, I create two global instances of sensors, initialize and run both of them. When both sensors are ready, I collect data and print them out on the serial monitor. From the serial monitor, we can see both sensors function correctly. I placed the sensors in proximity so the 20mm difference makes sense.  </p>  
              <img class="img-rounded" src="pics/lab3/lab3-4.png" alt="Generic placeholder image"  height="800">
              <hr>

              <h3>Tof sensor speed</h3>
              <p style="text-align: left;padding: 0px 30px;"> To test the measurement speed of sensors, I only use a single sensor -- sensor 1.  <br> I notice that in the example code, a while loop with delay of 1 second for each iteration is used (line 56 - 59), which can take a lot of time. By measuring the time difference between sensor 1 start ranging and sensor 1 stop ranging, I got the time for each measurement and printed it out. As shown in the monitor, it takes about 95-103 ms for each measurement to complete. </p>
              <img class="img-rounded" src="pics/lab3/lab3-5.png" alt="Generic placeholder image"  height="400">
              <p style="text-align: left;padding: 0px 30px;"> To improve the speed of measurement, I transformed the while loop with delay to a if condition without any delay. On line 56. if both sensors are ready, the program will move on to measure and print out result immediately. From the serial output, we can see that the measurement time is around 11ms each time, which is reduced significantly from the original code. </p>
              <img class="img-rounded" src="pics/lab3/lab3-6.png" alt="Generic placeholder image"  height="700">
              <p style="text-align: left;padding: 0px 30px;"> Moreover, I think another limiting factor is the maximum speed of data transfer from the sensor to the Arduino.</p>
              <hr>

              <h3>Time v Distance</h3>
              <p style="text-align: left;padding: 0px 30px;"> Editing my work from lab2, I add an additional command type -- GET_SENSOR. On the arduino side, this command type has a infinite while loop that constantly captures distance data from sensors and sent them along with time data to the PC. On the PC side, the notification handler is modified to take the new data and store them in a global sensor array. By printing out the content of the sensor array, we can see the timestamped sensor data. Note that since the loop on the board side is non-stopping, the sensor array is expanding all the time until it reaches its maximum capacity.</p>
              <img class="img-rounded" src="pics/lab3/lab3-13.png" alt="Generic placeholder image"  height="500">
              <img class="img-rounded" src="pics/lab3/lab3-12.png" alt="Generic placeholder image"  height="700">
              <hr>

              <h3>Infrared transmission based sensors</h3>
              <p style="text-align: left;padding: 0px 30px;">My information is from <a href="https://electricalfundablog.com/infrared-sensor/"> this site</a>. The mechanism of IR sensors involves the use of an IR transmitter and an IR receiver. The IR transmitter sends IR and gets reflected by objects and obstacles, and the IR receiver gets the reflected infrared. Based on the time of sending and receiving, as well as the intensity of the received IR, the sensor is able to find the distance. There are many different types of infrared sensors. Active IR sensor contains both transmitter and receiver, radiating energy, receving, and analyzing energy. Passive IR sensors, on the other hand, only contain detectors. They use objects as IR source and transmitter, capturing and analyzing energy radiated by the objects. Passive IR sensor contains Thermal Infrared Sensor and Quantum Infrared Sensor. Thermal Infrared sensors are independent of wavelength, use heat as energy source, are slow with their detection time and response time. Quantum Infrared Sensor are dependent on wavelengths, have high detection time and response time, and require frequent cooling for precise measurement. Our ToF sensor is a kind of active IR sensors. There is also aother common type of active IR sensors called LiDAR (Light Detection and Ranging), which uses lasers and is less affected by environment disturbances. </p>
              <hr>

              <h3>Colors and textures</h3>
              <p style="text-align: left;padding: 0px 30px;"> 
              (1) colors: I tested red, green, blue, white, black, orange, violet, purple, pink, grey, and the readings for different colors are almost identiacal to each other. Thus, I make a conclusion that colors do not affect measurement of our ToF sensors. <br>
              (2) textures: Things get interesting when it comes to textures. For rough surfaces like boxes, mouses, etc., the measurements are still very accurate. For very smooth surfaces like screens and mirrors, the measures distance is significantly larger than the actual distance. For example, for an actual distance of around 60mm, the measured result was around 110mm. My speculation is that for smooth surfaces, specular reflection actaully takes place instead of diffuse reflection for rough surfaces. Since the smooth surfaces I used were not perfectly smooth, there was still IR reflected back and get captured by the receiver, but the amount of IR light receive is much smaller compared to rough surfaces. Also, some IR might get reflected to other directions and take longer time to travel back to the receiver, thereby increasing the measured distance. For transparent objects like glasses, the measured readings were huge. For example, my glasses placed at a distance of 50mm result in a measurement of 2500mm. My speculation is that the IR actaully penetrate the glasses and get reflected by obstacles further far away. 
              </p>
              <hr>

      </div>

    <hr id='lab4'>
      <br>
      <div style="text-align:center;">
          <h2>Lab 4: IMU</h2>
          <h2>Introduction</h2>
          <p style="text-align: left;padding: 0px 30px;"> In lab 4, we explore the use of the <a href="https://cdn.sparkfun.com/assets/7/f/e/c/d/DS-000189-ICM-20948-v1.3.pdf"> ICM-20948 IMU</a>. After setting the IMU up, we tested its accelerometer and gyroscope by sampling data, plotting, and sending them via bluetooth. Meanwhile, we put the ToFs and IMU on the car, observing a stunt from playing the car. </p>
          <hr>

          <h2>Lab Tasks</h2>
            <h3>Set up the IMU</h3>
            <div align="center";> 
              <img class="img-rounded" src="pics/lab4/lab4-9.jpg" alt="Generic placeholder image", width="500", height="500">
              <img class="img-rounded" src="pics/lab4/lab4-10.jpg" alt="Generic placeholder image", width="500", height="500">
            </div>
            
            
            <p style="text-align: left;padding: 0px 30px;"> 
            In the left picture, 
            From the video, we can see that the 
            </p>
            <hr>




              
      </div>

    <hr id='lab5'>
    <br>
      <div style="text-align:center;">
              <h2>Lab 5</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>

    <hr id='lab6'>
    <br>
      <div style="text-align:center;">
              <h2>Lab 6</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>

    <hr id='about'>
    <br>
      <div class="row" style="text-align:center;">
            <h2>About Me</h2> 
            <div class="center-block" style="font-size:16px">
                <img class="img-rounded" src="pics/a.jpg" alt="Generic placeholder image" width="280" height="240">
                <h3>Michael Wu </h3>
                <p class="lead">yw2464@cornell.edu</p>
                <p style="text-align: left;padding: 0px 30px;"> I am a ECE Master of Engineering Studenting focusing on an embedded software track, so I am more than excited to take this class! I got my Bachelor of Science in EE at UCLA, where I studied analog circuit, CMOS, waves back then. I am more into Computer Engineering with embedded systems as they are more fun in my opinion!</p>
            </div>
      </div>

   <hr id='lab7'>
    <br>
      <div style="text-align:center;">
              <h2>Lab 7</h2>
              <p style="text-align: left;padding: 0px 30px;">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum lorem nulla, consectetur at leo vel, pretium bibendum nisl. Cras blandit quam a enim ultrices, eu convallis enim posuere. Donec eleifend enim sed purus consectetur, vitae cursus lectus varius. Vivamus consectetur felis nec est venenatis posuere. Phasellus vitae aliquet erat. In laoreet lacinia mollis. Quisque iaculis nisl fermentum pharetra lobortis. Donec rhoncus dui sem, ac molestie leo tristique vel. Phasellus in nibh feugiat, fringilla lectus in, elementum magna. Etiam quis dui condimentum, tempus ex in, dapibus est. Cras ut congue augue. Donec ac enim ex. Ut id tristique risus, vel porttitor quam. Sed ultricies enim eu nibh porttitor, vel sodales enim feugiat. Fusce volutpat venenatis magna ac ultrices. Curabitur eget urna ut nulla mattis convallis non eu diam.</p>
      </div>
<!--     <hr>

    <div class="row" style="text-align:center;">
          <h2>Work Distribution</h2>
          <div style="text-align:center;">
              <img class="img-rounded" src="pics/group.jpg" alt="Generic placeholder image" style="width:80%;">
              <h4>Project group picture</h4>
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/a.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Rick</h3>
              <p class="lead">netid@cornell.edu</p>
              <p>Designed the overall software architecture (Just being himself).
          </div>
          <div class="col-md-6" style="font-size:16px">
              <img class="img-rounded" src="pics/b.png" alt="Generic placeholder image" width="240" height="240">
              <h3>Morty</h3>
              <p class="lead">netid@cornell.edu</p>
              <p>Tested the overall system.
          </div>
      </div>

    <hr>
      <div style="font-size:18px">
          <h2>Parts List</h2>
          <ul>
              <li>Raspberry Pi $35.00</li>
              <li>Raspberry Pi Camera V2 $25.00</li>
              <a href="https://www.adafruit.com/product/1463"><li>NeoPixel Ring - $9.95</li></a>
              <li>LEDs, Resistors and Wires - Provided in lab</li>
          </ul>
          <h3>Total: $69.95</h3>
      </div>
      <hr>
      <div style="font-size:18px">
          <h2>References</h2>
          <a href="https://picamera.readthedocs.io/">PiCamera Document</a><br>
          <a href="http://www.micropik.com/PDF/SG90Servo.pdf">Tower Pro Servo Datasheet</a><br>
          <a href="http://getbootstrap.com/">Bootstrap</a><br>
          <a href="http://abyz.co.uk/rpi/pigpio/">Pigpio Library</a><br>
          <a href="https://sourceforge.net/p/raspberry-gpio-python/wiki/Home/">R-Pi GPIO Document</a><br>

      </div>
 -->
    <hr>

      <div class="row">
              <h2>Code Appendix</h2>
              <pre><code>
// Hello World.c
int main(){
  printf("Hello World.\n");
}
              </code></pre>
      </div>

    </div><!-- /.container -->




    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <!-- <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script> -->
  </body>
</html>
